{"page_content": "```\nLocal RAG Backend Setup Guide\n\nThis guide explains how to set up and run the local RAG (Retrieval-Augmented Generation) pipeline.\n\nStep 1: Install Ollama (Local LLM Server)\n\nThis is the \"server wrapper\" for your local LLaMA models.\n\nGo to ollama.com and download the application for your OS (macOS,\nWindows, or Linux).\n\nInstall it. After installation, Ollama runs as a background service.\n\nStep 2: Download the LLMs\n\nYou need two models: one for \"chat\" (generation) and one for \"embeddings\" (retrieval).\n\nOpen your terminal and run:\n\n# 1. Pull the main chat model (a light, powerful 3B model)\nollama pull llama3.2:3b\n\n# 2. Pull the embedding model (specialized for RAG)\nollama pull nomic-embed-text\n\n\nStep 3: Install Python Libraries\n\nInstall all the required Python packages from your requirements.txt file.\n\n# Create a virtual environment (recommended)\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install libraries\npip install -r requirements.txt\n\n\nStep 4: Add Your Documents\n\nPlace one or more PDF files you want to \"chat\" with into the /data folder.\n\nmy_notebook_app/\n\u2514\u2500\u2500 data/\n    \u2514\u2500\u2500 my_project_brief.pdf\n    \u2514\u2500\u2500 another_report.pdf\n\n\nStep 5: Run the Ingestion Script\n\nThis script reads your documents, creates embeddings, and saves them to the local vector store. You only need to run this once (or again if you add/change documents).\n\npython ingest.py\n\n\nExpected Output:\nYou will see progress bars and a final message:\nSuccessfully saved vector store to 'vector_store/faiss_index'\n\nStep 6: Test the RAG Flow (Run the CLI)\n\nNow you can run the CLI tool to chat with your documents.\n\npython query.py\n\n\nExpected Output:\nThe script will load the models and then prompt you for a question.\n\n--- Local RAG CLI ---\nLoading RAG chain...\nReady! Using LLM: 'llama3.2:3b' and Vector Store: 'vector_store/faiss_index'\nType 'exit' or 'quit' to end.\n\nAsk a question about your documents:\n>\n\n\nNext Steps", "metadata": {"source": "Internal Chatbot Knowledgebase", "type": "notion"}}